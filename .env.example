# Environment variables for LLM providers
NODE_ENV=development

# Choose your current LLM provider: openai, anthropic, ollama
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434

# Server Configuration
PORT=3001